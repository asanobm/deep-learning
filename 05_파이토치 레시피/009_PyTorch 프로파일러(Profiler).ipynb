{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch 프로파일러(Profiler)\n",
    "\n",
    "PyTorch프로파일러는 PyTorch 모델의 성능을 분석하는데 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 개요\n",
    "\n",
    "> PyTorch는 사용자가 모델 내의 연산 비용이 큰(expensive) 연산자들이 무엇인지 알고싶을 때 유용하게 사용할 수 있는 간단한 프로파일러 API를 포함하고 있습니다.\n",
    "> [출처: PyTorch](https://tutorials.pytorch.kr/recipes/recipes/profiler_recipe.html#id1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 ResNet 모델을 정의합니다.\n",
    "\n",
    "model = models.resnet18()\n",
    "inputs = torch.randn(5, 3, 244, 244)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-02-22 23:05:29 54014:54014 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-02-22 23:05:29 54014:54014 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-02-22 23:05:29 54014:54014 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "# 모델을 실행하면서 프로파일링을 수행합니다.\n",
    "with profile(activities=[ProfilerActivity.CPU],record_shapes=True) as prof:\n",
    "  with record_function(\"model_inference\"):\n",
    "    model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  model_inference         2.74%       1.796ms       100.00%      65.526ms      65.526ms             1  \n",
      "                     aten::conv2d         3.75%       2.460ms        77.10%      50.522ms       2.526ms            20  \n",
      "                aten::convolution         0.28%     186.000us        76.22%      49.942ms       2.497ms            20  \n",
      "               aten::_convolution         0.17%     111.000us        75.93%      49.756ms       2.488ms            20  \n",
      "         aten::mkldnn_convolution        75.06%      49.182ms        75.76%      49.645ms       2.482ms            20  \n",
      "                 aten::batch_norm         0.50%     328.000us         7.25%       4.751ms     237.550us            20  \n",
      "     aten::_batch_norm_impl_index         2.05%       1.343ms         7.20%       4.718ms     235.900us            20  \n",
      "                 aten::max_pool2d         0.01%       6.000us         6.17%       4.042ms       4.042ms             1  \n",
      "    aten::max_pool2d_with_indices         6.16%       4.036ms         6.16%       4.036ms       4.036ms             1  \n",
      "          aten::native_batch_norm         5.06%       3.318ms         5.14%       3.370ms     168.500us            20  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 65.526ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls                                                                      Input Shapes  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "                  model_inference         2.74%       1.796ms       100.00%      65.526ms      65.526ms             1                                                                                []  \n",
      "                     aten::conv2d         0.80%     527.000us        19.48%      12.765ms      12.765ms             1                             [[5, 3, 244, 244], [64, 3, 7, 7], [], [], [], [], []]  \n",
      "                     aten::conv2d         0.03%      17.000us        18.98%      12.436ms       3.109ms             4                             [[5, 64, 61, 61], [64, 64, 3, 3], [], [], [], [], []]  \n",
      "                aten::convolution         0.10%      63.000us        18.95%      12.419ms       3.105ms             4                     [[5, 64, 61, 61], [64, 64, 3, 3], [], [], [], [], [], [], []]  \n",
      "               aten::_convolution         0.05%      35.000us        18.86%      12.356ms       3.089ms             4     [[5, 64, 61, 61], [64, 64, 3, 3], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "         aten::mkldnn_convolution        18.46%      12.099ms        18.80%      12.321ms       3.080ms             4                             [[5, 64, 61, 61], [64, 64, 3, 3], [], [], [], [], []]  \n",
      "                aten::convolution         0.05%      30.000us        18.68%      12.238ms      12.238ms             1                     [[5, 3, 244, 244], [64, 3, 7, 7], [], [], [], [], [], [], []]  \n",
      "               aten::_convolution         0.02%      11.000us        18.63%      12.208ms      12.208ms             1     [[5, 3, 244, 244], [64, 3, 7, 7], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "         aten::mkldnn_convolution        18.57%      12.165ms        18.61%      12.197ms      12.197ms             1                             [[5, 3, 244, 244], [64, 3, 7, 7], [], [], [], [], []]  \n",
      "                     aten::conv2d         0.01%       5.000us        10.86%       7.119ms       2.373ms             3                            [[5, 512, 8, 8], [512, 512, 3, 3], [], [], [], [], []]  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "Self CPU time total: 65.526ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages(group_by_input_shape=True).table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  model_inference        26.79%     625.000us       100.00%       2.333ms       2.333ms             1  \n",
      "                     aten::conv2d         6.17%     144.000us        28.80%     672.000us      33.600us            20  \n",
      "                aten::convolution         3.17%      74.000us        27.95%     652.000us      32.600us            20  \n",
      "               aten::_convolution         1.80%      42.000us        24.77%     578.000us      28.900us            20  \n",
      "          aten::cudnn_convolution        22.97%     536.000us        22.97%     536.000us      26.800us            20  \n",
      "                       aten::add_         7.84%     183.000us         7.84%     183.000us       6.536us            28  \n",
      "                 aten::batch_norm         2.27%      53.000us        18.69%     436.000us      21.800us            20  \n",
      "     aten::_batch_norm_impl_index         1.03%      24.000us        18.00%     420.000us      21.000us            20  \n",
      "           aten::cudnn_batch_norm        14.66%     342.000us        16.97%     396.000us      19.800us            20  \n",
      "                 aten::empty_like         0.99%      23.000us         1.89%      44.000us       2.200us            20  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.333ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-02-22 23:12:02 54014:54014 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-02-22 23:12:02 54014:54014 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-02-22 23:12:02 54014:54014 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18().cuda()\n",
    "inputs = torch.randn(5, 3, 224, 224).cuda()\n",
    "\n",
    "with profile(activities=[\n",
    "        ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        model(inputs)\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                      aten::empty         0.49%     256.000us         0.49%     256.000us       1.280us      83.36 Mb      83.36 Mb           200  \n",
      "    aten::max_pool2d_with_indices         5.39%       2.810ms         5.39%       2.810ms       2.810ms      11.48 Mb      11.48 Mb             1  \n",
      "                 aten::empty_like         0.08%      41.000us         0.14%      71.000us       3.550us      47.37 Mb       7.66 Mb            20  \n",
      "     aten::_batch_norm_impl_index         0.55%     289.000us         6.92%       3.605ms     180.250us      47.41 Mb       3.83 Mb            20  \n",
      "         aten::mkldnn_convolution        84.06%      43.812ms        84.43%      44.006ms       2.200ms      47.37 Mb       3.83 Mb            20  \n",
      "                      aten::addmm         0.18%      93.000us         0.20%     103.000us     103.000us      19.53 Kb      19.53 Kb             1  \n",
      "        aten::adaptive_avg_pool2d         0.15%      78.000us         0.15%      78.000us      78.000us      10.00 Kb      10.00 Kb             1  \n",
      "                       aten::mean         0.03%      15.000us         0.14%      75.000us      75.000us      10.00 Kb       9.99 Kb             1  \n",
      "                       aten::div_         0.03%      15.000us         0.07%      35.000us      35.000us           8 b           4 b             1  \n",
      "              aten::empty_strided         0.01%       3.000us         0.01%       3.000us       3.000us           4 b           4 b             1  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 52.123ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-02-22 23:12:32 54014:54014 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-02-22 23:12:32 54014:54014 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-02-22 23:12:32 54014:54014 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "# 프로파일러를 사용하여 메모리 소비 분석하기\n",
    "\n",
    "model = models.resnet18()\n",
    "inputs = torch.randn(5, 3, 224, 224)\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU],\n",
    "        profile_memory=True, record_shapes=True) as prof:\n",
    "    model(inputs)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                      aten::empty         0.49%     256.000us         0.49%     256.000us       1.280us      83.36 Mb      83.36 Mb           200  \n",
      "                 aten::batch_norm        -0.28%    -144.000us         7.01%       3.652ms     182.600us      47.41 Mb      -3.83 Mb            20  \n",
      "     aten::_batch_norm_impl_index         0.55%     289.000us         6.92%       3.605ms     180.250us      47.41 Mb       3.83 Mb            20  \n",
      "          aten::native_batch_norm         6.41%       3.341ms         6.72%       3.501ms     175.050us      47.41 Mb     -59.50 Kb            20  \n",
      "                     aten::conv2d         0.17%      88.000us        85.25%      44.435ms       2.222ms      47.37 Mb           0 b            20  \n",
      "                aten::convolution         0.40%     211.000us        85.08%      44.347ms       2.217ms      47.37 Mb           0 b            20  \n",
      "               aten::_convolution         0.25%     130.000us        84.68%      44.136ms       2.207ms      47.37 Mb           0 b            20  \n",
      "         aten::mkldnn_convolution        84.06%      43.812ms        84.43%      44.006ms       2.200ms      47.37 Mb       3.83 Mb            20  \n",
      "                 aten::empty_like         0.08%      41.000us         0.14%      71.000us       3.550us      47.37 Mb       7.66 Mb            20  \n",
      "                 aten::max_pool2d         0.01%       4.000us         5.40%       2.814ms       2.814ms      11.48 Mb           0 b             1  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 52.123ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-02-22 23:16:21 54014:54014 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-02-22 23:16:21 54014:54014 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-02-22 23:16:21 54014:54014 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18().cuda()\n",
    "inputs = torch.randn(5, 3, 224, 224).cuda()\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA]) as prof:\n",
    "    model(inputs)\n",
    "\n",
    "prof.export_chrome_trace(\"trace.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     aten::conv2d         6.63%     157.000us        35.26%     835.000us      41.750us            20  \n",
      "                aten::convolution         3.46%      82.000us        33.99%     805.000us      40.250us            20  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.368ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-02-22 23:14:31 54014:54014 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-02-22 23:14:31 54014:54014 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-02-22 23:14:31 54014:54014 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "    with_stack=True,\n",
    ") as prof:\n",
    "    model(inputs)\n",
    "\n",
    "# Print aggregated stats\n",
    "print(prof.key_averages(group_by_stack_n=5).table(sort_by=\"self_cuda_time_total\", row_limit=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
