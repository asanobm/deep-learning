{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. 텍스트를 임베딩으로 변환하기\n",
    "\n",
    "- 컴퓨터는 텍스트를 그대로 이해할 수 없기 때문에, 텍스트를 숫자로 변환해야 한다. 텍스트를 적잘한 단위로 잘라서 아이디로 변환하는 것을 토크나이징(tokenizing)이라고 한다.\n",
    "- 토큰 아이디를 토큰 임베딩 층을 통해 여러 숫자의 집합인 토큰 임베딩으로 변환한다.\n",
    "- 위치 인코딩 층을 통해 토큰의 위치 정보를 담고 있는 위치 임베딩을 추가한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. 토큰화\n",
    "\n",
    "토큰화란 텍스트를 적절한 단위로 나누고 숫자 아이디를 부여하는 것을 말한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰화 결과:  ['나는', '최근', '파리', '여행을', '다녀왔다']\n",
      "토큰 -> 아이디 딕셔너리:  {'나는': 0, '최근': 1, '파리': 2, '여행을': 3, '다녀왔다': 4}\n",
      "아이디 -> 토큰 딕셔너리:  {0: '나는', 1: '최근', 2: '파리', 3: '여행을', 4: '다녀왔다'}\n",
      "토큰을 아이디로 변환:  [0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "# 예제 2.1 토큰화 (띄어쓰기 기준)\n",
    "input_text = \"나는 최근 파리 여행을 다녀왔다\"\n",
    "\n",
    "input_text_list = input_text.split()\n",
    "print(\"토큰화 결과: \", input_text_list)\n",
    "\n",
    "# 토큰 -> 아이디 딕셔너리 생성\n",
    "str2dix = {word: i for i, word in enumerate(input_text_list)}\n",
    "print(\"토큰 -> 아이디 딕셔너리: \", str2dix)\n",
    "# 아이디 -> 토큰 딕셔너리 생성\n",
    "dix2str = {i: word for i, word in enumerate(input_text_list)}\n",
    "print(\"아이디 -> 토큰 딕셔너리: \", dix2str)\n",
    "\n",
    "# 토큰을 토큰 아이디로 변환\n",
    "input_ids = [str2dix[word] for word in input_text_list]\n",
    "print(\"토큰을 아이디로 변환: \", input_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. 토큰 임페딩으로 변환하기\n",
    "\n",
    "**임베딩이란?**\n",
    "\n",
    "데이터를 의미를 담아 숫자 벡터로 변환하는 것을 말한다\n",
    "\n",
    "**토큰 임베딩이란?**\n",
    "\n",
    "...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 결과:  torch.Size([1, 5, 16])\n"
     ]
    }
   ],
   "source": [
    "# 2.2 토큰 아이디에서 벡터로 변환\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "embedding_dim = 16 # 임베딩 차원\n",
    "embed_layer = nn.Embedding(len(str2dix), embedding_dim) # 임베딩 레이어 생성\n",
    "\n",
    "input_embeddings = embed_layer(torch.tensor(input_ids)) # 토큰 아이디를 임베딩 벡터로 변환\n",
    "input_embeddings = input_embeddings.unsqueeze(0) # 배치 차원 추가\n",
    "print(\"임베딩 결과: \", input_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3. 위치 인코딩\n",
    "\n",
    "토큰 임베딩은 단어의 의미를 담고 있지만, 단어의 순서 정보는 담고 있지 않다. 따라서 위치 인코딩을 추가해야 한다.\n",
    "\n",
    "**위치 인코딩이란?**\n",
    "\n",
    "토큰의 위치 정보를 담고 있는 위치 임베딩을 추가하는 것을 말한다.\n",
    "\n",
    "**위치 인코딩 방법**\n",
    "\n",
    "**절대적 위치 인코딩(Absolute Positional Encoding)**\n",
    "\n",
    "절대적 위치 인코딩은 토큰의 위치 정보를 나타내는 벡터를 추가하는 것이다. 이 방법은 토큰의 위치 정보가 고정되어 있다.\n",
    "  \n",
    "**상대적 위치 인코딩(Relative Positional Encoding)**\n",
    "\n",
    "상대적 위치 인코딩은 토큰의 위치 정보를 나타내는 벡터를 추가하는 것이다.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "절대적 위치 인코딩 결과:  torch.Size([1, 5, 16])\n"
     ]
    }
   ],
   "source": [
    "# 예제 2.3 절대적 위치 인코딩\n",
    "\n",
    "embedding_dim = 16 # 임베딩 차원\n",
    "max_position = 12 # 최대 토큰 길이\n",
    "\n",
    "embed_layer = nn.Embedding(len(str2dix), embedding_dim) # 임베딩 레이어 생성\n",
    "position_embed_layer = nn.Embedding(max_position, embedding_dim) # 위치 임베딩 레이어 생성\n",
    "\n",
    "position_ids = torch.arange(len(input_ids), dtype=torch.long).unsqueeze(0) # 토큰 길이만큼 위치 아이디 생성\n",
    "position_encodings = position_embed_layer(position_ids) # 위치 아이디를 임베딩 벡터로 변환\n",
    "\n",
    "token_embeddings = embed_layer(torch.tensor(input_ids)) # 토큰 아이디를 임베딩 벡터로 변환\n",
    "token_embeddings = token_embeddings.unsqueeze(0) # 배치 차원 추가\n",
    "token_embeddings = token_embeddings + position_encodings # 토큰 임베딩과 위치 임베딩을 더함\n",
    "print(\"절대적 위치 인코딩 결과: \", token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
