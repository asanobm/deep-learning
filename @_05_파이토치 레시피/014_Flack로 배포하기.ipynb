{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flack로 배포하기\n",
    "\n",
    "* 학습한 PyTorch모델을 Flack컨테이너로 감싸고 웹 API로 노출\n",
    "* 웹 요청을 모델에 입력하기 위해 PyTorch 텐서로 변경\n",
    "* 모델 결과를 HTTP응답으로 패키징"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from flask import Flask, jsonify, request\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "model = models.densenet121(pretrained=True)               # ImageNet의 1000개 클래스를 학습\n",
    "model.eval()                                              # autograd 끄기\n",
    "\n",
    "\n",
    "\n",
    "img_class_map = None\n",
    "mapping_file_path = 'index_to_name.json'                  # 사람이 읽을 수 있는 ImageNet 클래스 이름\n",
    "if os.path.isfile(mapping_file_path):\n",
    "    with open (mapping_file_path) as f:\n",
    "        img_class_map = json.load(f)\n",
    "\n",
    "\n",
    "\n",
    "# Transform input into the form our model expects\n",
    "def transform_image(infile):\n",
    "    input_transforms = [transforms.Resize(255),           # 이미지 준비를 위해 여러 TorchVision transforms 사용\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],       # ImageNet 모델 입력에 대한 표준 정규화\n",
    "            [0.229, 0.224, 0.225])]\n",
    "    my_transforms = transforms.Compose(input_transforms)\n",
    "    image = Image.open(infile)                            # 이미지 파일 열기\n",
    "    timg = my_transforms(image)                           # PIL 이미지를 적절한 모양의 PyTorch 텐서로 변환\n",
    "    timg.unsqueeze_(0)                                    # PyTorch 모델은 배치 입력을 예상하므로 1짜리 배치를 만듦\n",
    "    return timg\n",
    "\n",
    "\n",
    "# Get a prediction\n",
    "def get_prediction(input_tensor):\n",
    "    outputs = model.forward(input_tensor)                 # 모든 ImageNet 클래스에 대한 가능성(likelihood) 얻기\n",
    "    _, y_hat = outputs.max(1)                             # 가장 가능성 높은 클래스 추출\n",
    "    prediction = y_hat.item()                             # PyTorch 텐서에서 int 값 추출\n",
    "    return prediction\n",
    "\n",
    "# Make the prediction human-readable\n",
    "def render_prediction(prediction_idx):\n",
    "    stridx = str(prediction_idx)\n",
    "    class_name = 'Unknown'\n",
    "    if img_class_map is not None:\n",
    "        if stridx in img_class_map is not None:\n",
    "            class_name = img_class_map[stridx][1]\n",
    "\n",
    "    return prediction_idx, class_name\n",
    "\n",
    "\n",
    "@app.route('/', methods=['GET'])\n",
    "def root():\n",
    "    return jsonify({'msg' : 'Try POSTing to the /predict endpoint with an RGB image attachment'})\n",
    "\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    if request.method == 'POST':\n",
    "        file = request.files['file']\n",
    "        if file is not None:\n",
    "            input_tensor = transform_image(file)\n",
    "            prediction_idx = get_prediction(input_tensor)\n",
    "            class_id, class_name = render_prediction(prediction_idx)\n",
    "            return jsonify({'class_id': class_id, 'class_name': class_name})\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
