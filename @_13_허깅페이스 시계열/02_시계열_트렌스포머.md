# 시계열 트랜스포머 

시계열 트랜트포머 모델은 시계열 예측을 위한 기본적인 인코더-디코더 구조의 트랜스포머다.

## 2개의 클래스

* TimeSeriesTransformerModel: 상당에 헤드가 없는 기본적인 트랜스포머
* TimeSeriesTransformerForPrediction: 상단에 분포 호데를 추가하여 시계열 예측에 사용할 수 있다. (확률적 예측 모델) 값을 직접 출력하지는 않는다.

## TimeSeriesTransformerForPrediction의 2가지 블록

인코더는`context_length`의 시계열 값을 입력(`past_values`)으로 받고, 디코더는 미래의 `prediction_length` 만큼의 시계열 값을 예측한다(`future_values`). 학습에는 `past_values`와 `future_values`를 제공해야한다.

## 가공하지 않은 past_values와 future_values 이외의 추가 특징

* `past_time_features`: 모델이 `future_values`에 추가할 시간적 특성. 트랜스포머 디코더의 "위치 인코딩" 역할을 한다.
* `future_time_features`: 모델이 `future_values`에 추가할 시간적 특성. 트랜스포머 디코더의 "위치 인코딩" 역할을 한다.
* `static_categorical_features`: 시간에 따라 변하지 않는 범주형 특성 모든 `past_values`, `future_values`에 동일한 값을 가진다. (ID, 카테고리 등)
* `static_real_features`: 시간에 따라 변하지 않는 실수값 특성 모든 `past_values`, `future_values`에 동일한 값을 가진다. (온도, 고도 등) 

## 모델의 훈련
시계열 트랜스포머 모델은 기계 번역을 위한 트랜스포머 훈련과 유사하게 "교사 강제(teacher-forcing)" 방식으로 훈련된다. 즉 훈련중에 `future_values`를 디코더의 입력으로 오른쪽으로 한 위치 이동시키고, `past_values`의 마지막 값을 앞에 붙인다. 각 시간 단계에서 모델은 다음 타겟을 예측해야 한다. 따라서 훈련 설정은 언어를 위한 GPT 모델과 유사하지만, `decoder_start_token_id` 개념이 없다. 

## 모델의 추론

추론 시에는 `past_values`의 최종값을 디코더의 입력으로 제공한다. 그 다음, 모델에서 샘플링하여 다음 시간 단계에서의 예측을 만들고, 이를 디코더에 공급하여 다음 예측을 만든다.

## TimeSeriesTransformerConfig class

### Parameters

* `prediction_length`: (int), **예측길이**모델이 얼마나 멀리 미래를 예측할 지를 정의한다.
* `context_length`: (int, optional, defaults to `prediction_length`),**컨텍스트 길이** 모델에게 더 많은 과거 정보를 제공하여 더 나은 예측을 할 수 있도록 도와준다. 데이터 세트의 특성에 따라 이를 조정하는 것이 성능 향상에 도움이 될 수 있다.
* `distribution_output`: (string, optional, defaults "student_t"), **분포 출력** 올바른 분포를 선택하는 것("student_t", "normal", "negative_binomial")은 모델이 예측의 불확실성과 꼬리를 추정하는 방식에 영향을 준다
* `loss`: (string, optional, defaults to :"nll"), **손실함수** 현재는 음의 로그 우도("nagative log liklihood")만 지원한다.
* `input_size`: (int, optional, defaults to 1), **입력 크기** 단항 예측(univariate)에서 중요하다. 모델의 고려하는 타깃 변수의 수에 직접 영향을 미친다.
* `scaling`: (string, or bool, optional, defaults to "mean"), **스케일링** 입력 특징을 적절히 스케일링(mean, standard deviation)하는 것은 모델 수렴의 및 성능에 상당한 영향을 준다.
* `lags_sequence`: (list[int], optional, defaults to [1, 2, 3, 4, 5, 6, 7]), **지연 시퀀스** 시계열의 빈도에 따라 자연 특징을 맞춤 설정하면 시간적 의존성을 효과적으로 포착하는데 도움이 된다.
* `num_time_features`: (int, optional, defaults to 0), **시간 특징 수** 시간 특징을 추가하면 모델이 시간적 특성을 더 잘 이해하고 예측할 수 있다.
* `num_dynamic_real_features`: (int, optional, defaults to 0), **동적 실수 특징 수** 시간에 따라 변하는 실수값 특성
* `num_static_real_features`: (int, optional, defaults to 0), **정적 실수 특징 수** 시간에 따라 변하지 않는 실수값 특성
* `num_static_real_features`: (int, optional, defaults to 0), **정적 범주형 특징 수** 시간에 따라 변하지 않는 범주형 특성
* `cardinality`: (list[int], optional) **카디널리티** 각 정적 범주형 특성에 대한 카디널리티 `num_static_categorical_features`와 같은 길이의 정수 목록이어야 한며, `num_static_categorical_features`가 0보다 큰 경우 None일 수 없다.
* `embedding_dimension`: (list[int], optional), 각 정적 범주형 특성에 다한 임베딩차원 `num_static_categorical_features`와 같은 길이의 정수 목록이여야하며, `num_static_categorical_features`가 0보다 큰 경우 None일 수 없다.
* `d_model`: (int, optional, defaults to 64) 변형기 레이어의 차원
* `encoder_layers`: (int, optional, defaults to 2) 인코더 레이어의 수
* `decoder_layers`: (int, optional, defaults to 2) 디코더 레이어의 수
* `encoder_attention_heads`: (int, optional, defaults to 2) 변형 인코더의 각 주의 레이어에 대한 주의 헤드 수
* `decoder_attention_heads`: (int, optional, defaults to 2) 변형 디코더의 각 주의 레이어에 대한 주의 헤드 수
* `encoder_ffn_dim`: (int, optional, defaults to 32) 인코더의 "중간 (feed forward)" 차원
* `decoder_ffn_dim`: (int, optional, defaults to 32) 디코더의 "중간 (feed forward)" 차원
* `activation_function`: (str, function, optional, defaults to "gelu") 인코더와 디코더의 활성화 함수
* `dropout`: (float, optional, defaults to 0.1) 인코더와 디코더의 드롭아웃
* `encoder_layerdrop`: (float, optional, defaults to 0.1) 인코더 레이어 드롭
* `decoder_layerdrop`: (float, optional, defaults to 0.1) 디코더 레이어 드롭
* `attention_dropout`: (float, optional, defaults to 0.1) 어텐션 드롭아웃
* `activation_dropout`: (float, optional, defaults to 0.1) 활성화 드롭아웃
* `num_parallel_samples`: (int, optional, defaults to 100) 추론 시에 생성할 샘플 수
* `init_std`: (float, optional, defaults to 0.02) 초기화 표준 편차
* `use_cache`: (bool, optional, defaults to False) 캐시 사용 여부

## TimeSeriesTransformerModel class

* config: TimeSeriesTransformerConfig 

분류 헤드가 없는 기본적인 시계열 트랜스포머 모델. 이 모델은 PreTrained에서 상속된다. 

### Parameters

* `past_values` (`torch.FloatTensor` of shape (`batch_size`, `sequence_length`) or (`batch_size`, `sequence_length`, `input_size`)) — 미래를 예측하기 위해 컨텍스트 역할을 하는 시계열의 과거 값입니다. 이 텐서의 시퀀스 크기는 모델의 `context_length`보다 커야 하며, 모델은 더 큰 크기를 사용하여 지연 특징(추가 컨텍스트 역할을 하는 과거의 추가 값)을 구성합니다.
  
`sequence_length`는 `config.context_length` + `max(config.lags_sequence)`와 같으며, lags_sequence가 설정되지 않은 경우 기본적으로 `config.context_length` + 7과 같습니다(`config.lags_sequence`에서 가장 큰 look-back 인덱스는 7입니다). 속성 `_past_length`는 과거의 실제 길이를 반환합니다.

`past_values`는 트랜스포머 인코더가 입력으로 받는 값입니다 (선택적으로 추가 특징, 예를 들어 `static_categorical_features`, `static_real_features`, `past_time_features` 및 lags 포함). 선택적으로, 결측값은 0으로 대체하고 `past_observed_mask`를 통해 표시해야 합니다.

다변량 시계열의 경우, `input_size` > 1 차원이 필요하며 이는 시간 단계별 시계열의 변량 수에 해당합니다.

* `past_time_features` (`torch.FloatTensor` of shape (`batch_size`, `sequence_length`, `num_features`)) — 모델이 `past_values`에 내부적으로 추가할 필수 시간 특징입니다. 이러한 특징은 "월", "일" 등 벡터로 인코딩된 것일 수 있습니다(for instance as Fourier features). 또한, 시계열이 "어느 시점에 있는지"를 모델이 알 수 있도록 돕는 "age" 특징일 수도 있습니다. age 특징은 먼 과거 시간 단계에서는 작은 값을 가지며 현재 시간 단계에 가까워질수록 단조롭게 증가합니다. 휴일 특징도 시간 특징의 좋은 예입니다.
이러한 특징은 입력의 "위치 인코딩" 역할을 합니다. 따라서 BERT와 같은 모델에서는 위치 인코딩이 모델의 내부 매개변수로부터 처음부터 학습되는 반면, 시계열 트랜스포머는 추가 시간 특징을 제공해야 합니다. 시계열 트랜스포머는 `static_categorical_features`에 대한 추가 임베딩만 학습합니다.

추가 동적 실수 공변량은 이 텐서에 연결할 수 있지만, 이러한 특징은 예측 시점에 알려져 있어야 합니다.

`num_features`는 `config.num_time_features` + `config.num_dynamic_real_features`와 같습니다.

* `past_observed_mask` (`torch.BoolTensor` of shape (`batch_size`, `sequence_length`) or (`batch_size`, `sequence_length`, `input_size`), optional) — 과거 값이 관찰되었는지 또는 누락되었는지를 나타내는 부울 마스크입니다. 마스크 값은 [0, 1]에서 선택됩니다:
  * 1은 관찰된 값
  * 0은 누락된 값(즉, 0으로 대체된 NaN 값).

* `static_categorical_features` (`torch.LongTensor` of shape (`batch_size`, number of static categorical features), optional) — 모델이 임베딩을 학습하고 시계열 값에 추가할 정적 범주형 특징.
정적 범주형 특징은 모든 시간 단계에 대해 동일한 값을 갖는 특징입니다(시간에 따라 정적).

정적 범주형 피처의 일반적인 예는 시계열 ID입니다.

* `static_real_features` (`torch.FloatTensor` of shape (`batch_size`, number of static real features), optional) — 모델이 시계열 값에 추가할 정적 실수 특징.
정적 실수 특징은 모든 시간 단계에 대해 동일한 값을 갖는 특징입니다(시간에 따라 정적).

정적 실수 특징의 일반적인 예는 프로모션 정보입니다.

* `future_values` (`torch.FloatTensor` of shape (`batch_size`, `prediction_length`) or (`batch_size`, `prediction_length`, `input_size`), optional) — 모델의 레이블 역할을 하는 시계열의 미래 값입니다. `future_values`는 과거 값을 고려하여 출력하는 법을 배우기 위해 Transformer가 학습하는 동안 필요한 것입니다.
여기서 시퀀스 길이는 `prediction_length`와 같습니다.

훈련 중에는 결측값을 0으로 대체하고 `future_observed_mask`를 통해 표시해야 합니다.

다변량 시계열의 경우, `input_size` > 1 차원이 필요하며 이는 시간 단계별 시계열의 변량 수에 해당합니다.

* `future_time_features` (`torch.FloatTensor` of shape (`batch_size`, `prediction_length`, `num_features`)) — 예측 창에 필요한 시간 특징으로, 모델이 내부적으로 `future_values`에 추가합니다. 이러한 특징은 "월", "일" 등 벡터로 인코딩된 것일 수 있습니다(for instance as Fourier features). 또한, 시계열이 "어느 시점에 있는지"를 모델이 알 수 있도록 돕는 "age" 특징일 수도 있습니다. age 특징은 먼 과거 시간 단계에서는 작은 값을 가지며 현재 시간 단계에 가까워질수록 단조롭게 증가합니다. 휴일 특징도 시간 특징의 좋은 예입니다.
이러한 특징은 입력의 "위치 인코딩" 역할을 합니다. 따라서 BERT와 같은 모델에서는 위치 인코딩이 모델의 내부 매개변수로부터 처음부터 학습되는 반면, 시계열 트랜스포머는 추가 시간 특징을 제공해야 합니다. 시계열 트랜스포머는 `static_categorical_features`에 대한 추가 임베딩만 학습합니다.

추가 동적 실수 공변량은 이 텐서에 연결할 수 있지만, 이러한 특징은 예측 시점에 알려져 있어야 합니다.

`num_features`는 `config.num_time_features` + `config.num_dynamic_real_features`와 같습니다.

* `future_observed_mask` (`torch.BoolTensor` of shape (`batch_size`, `sequence_length`) or (`batch_size`, `sequence_length`, `input_size`), optional) — 미래 값이 관찰되었는지 또는 누락되었는지를 나타내는 부울 마스크입니다. 마스크 값은 [0, 1]에서 선택됩니다:
  * 1은 관찰된 값
  * 0은 누락된 값(즉, 0으로 대체된 NaN 값).

이 마스크는 최종 손실 계산에서 누락된 값을 필터링하는 데 사용됩니다.

* `attention_mask` (`torch.Tensor` of shape (`batch_size`, `sequence_length`), optional) — 특정 토큰 인덱스에 대해 어텐션을 수행하지 않도록 마스킹합니다. 마스크 값은 [0, 1]에서 선택됩니다:
  * 1은 마스킹되지 않은 토큰
  * 0은 마스킹된 토큰

어텐션 마스크란 무엇인가요?

* `decoder_attention_mask` (`torch.LongTensor` of shape (`batch_size`, `target_sequence_length`), optional) — 특정 토큰 인덱스에 대해 어텐션을 수행하지 않도록 마스킹합니다. 기본적으로 인과 마스크가 사용되어 모델이 미래를 예측하기 위해 이전 입력만 볼 수 있도록 합니다.

* `head_mask` (`torch.Tensor` of shape (`encoder_layers`, `encoder_attention_heads`), optional) — 인코더의 어텐션 모듈에서 선택된 헤드를 무효화하는 마스크입니다. 마스크 값은 [0, 1]에서 선택됩니다:
  * 1은 헤드가 마스킹되지 않음을 나타냅니다.
  * 0은 헤드가 마스킹됨을 나타냅니다.

* `decoder_head_mask` (`torch.Tensor` of shape (`decoder_layers`, `decoder_attention_heads`), optional) — 디코더의 어텐션 모듈에서 선택된 헤드를 무효화하는 마스크입니다. 마스크 값은 [0, 1]에서 선택됩니다:
  * 1은 헤드가 마스킹되지 않음을 나타냅니다.
  * 0은 헤드가 마스킹됨을 나타냅니다.

* `cross_attn_head_mask` (`torch.Tensor` of shape (`decoder_layers`, `decoder_attention_heads`), optional) — 교차 어텐션 모듈에서 선택된 헤드를 무효화하는 마스크입니다. 마스크 값은 [0, 1]에서 선택됩니다:
  * 1은 헤드가 마스킹되지 않음을 나타냅니다.
  * 0은 헤드가 마스킹됨을 나타냅니다.

* `encoder_outputs` (tuple(tuple(`torch.FloatTensor`), optional) — `last_hidden_state`, `hidden_states` (optional) 및 attentions (optional)로 구성된 튜플입니다. `last_hidden_state`의 형태는 (`batch_size`, `sequence_length`, `hidden_size`)이며, 인코더의 마지막 레이어 출력에서의 시퀀스 숨겨진 상태입니다. 디코더의 교차 어텐션에서 사용됩니다.

* `past_key_values` (tuple(tuple(`torch.FloatTensor`)), optional, `use_cache=True`가 전달되거나 `config.use_cache=True`일 때 반환됩니다) — 길이가 `config.n_layers`인 tuple(`torch.FloatTensor`)의 튜플로, 각 튜플은 형태가 (`batch_size`, `num_heads`, `sequence_length`, `embed_size_per_head`))인 2개의 텐서와 형태가 (`batch_size`, `num_heads`, `encoder_sequence_length`, `embed_size_per_head`)인 추가 2개의 텐서를 가집니다.
사전 계산된 숨겨진 상태(자기 어텐션 블록 및 교차 어텐션 블록의 키와 값)를 포함하며, 이는 순차적 디코딩을 가속화하는 데 사용할 수 있습니다(입력으로 past_key_values 참조).

`past_key_values`가 사용되는 경우, 사용자는 모델에 전달된 past key value 상태가 없는 마지막 `decoder_input_ids`(형태: (`batch_size`, 1))만 입력할 수 있으며, 모든 decoder_input_ids(형태: (`batch_size`, `sequence_length`))를 입력할 필요는 없습니다.

* `inputs_embeds` (`torch.FloatTensor` of shape (batch_size, sequence_length, hidden_size), optional) — 선택적으로, input_ids를 전달하는 대신 임베딩된 표현을 직접 전달할 수 있습니다. 이는 input_ids 인덱스를 관련 벡터로 변환하는 방법을 모델의 내부 임베딩 조회 매트릭스보다 더 많이 제어하고자 할 때 유용합니다.

* `use_cache` (bool, optional) — True로 설정된 경우, past_key_values 키 값 상태가 반환되며 디코딩 속도를 높이는 데 사용할 수 있습니다(입력으로 past_key_values 참조).

* `output_attentions` (bool, optional) — 모든 어텐션 레이어의 어텐션 텐서를 반환할지 여부를 나타냅니다. 자세한 내용은 반환된 텐서의 attentions를 참조하세요.

* `output_hidden_states` (bool, optional) — 모든 레이어의 숨겨진 상태를 반환할지 여부를 나타냅니다. 자세한 내용은 반환된 텐서의 hidden_states를 참조하세요.

* `return_dict` (bool, optional) — plain tuple 대신 ModelOutput을 반환할지 여부를 나타냅니다.


### Returns

transformers.modeling.outputs.Seq2SeqModelOutput 또는 tuple(torch.FloatTensor)

* `last_hidden_state` (torch.FloatTensor 형태 (batch_size, sequence_length, hidden_size)) — 모델의 디코더 마지막 레이어 출력에서의 숨겨진 상태 시퀀스.

`past_key_values`가 사용되는 경우, 시퀀스의 마지막 숨겨진 상태만 (batch_size, 1, hidden_size) 형태로 출력됩니다.
`past_key_values` (tuple(tuple(torch.FloatTensor)), 선택적, use_cache=True가 전달되거나 config.use_cache=True일 때 반환됨) — 길이가 config.n_layers인 tuple(torch.FloatTensor)의 튜플로, 각 튜플은 형태가 (batch_size, num_heads, sequence_length, embed_size_per_head)인 2개의 텐서와 형태가 (batch_size, num_heads, encoder_sequence_length, embed_size_per_head)인 추가 2개의 텐서를 가집니다.

사전 계산된 숨겨진 상태(자기 어텐션 블록 및 교차 어텐션 블록의 키와 값)를 포함하며, 이는 순차적 디코딩을 가속화하는 데 사용할 수 있습니다(입력으로 past_key_values 참조).

* `decoder_hidden_states` (tuple(torch.FloatTensor), 선택적, output_hidden_states=True가 전달되거나 config.output_hidden_states=True일 때 반환됨) — torch.FloatTensor의 튜플 (모델에 임베딩 레이어가 있는 경우 임베딩 출력 + 각 레이어의 출력)로, 형태는 (batch_size, sequence_length, hidden_size)입니다.

각 레이어 출력에서의 디코더의 숨겨진 상태와 선택적 초기 임베딩 출력.

* `decoder_attentions` (tuple(torch.FloatTensor), 선택적, output_attentions=True가 전달되거나 config.output_attentions=True일 때 반환됨) — torch.FloatTensor의 튜플 (각 레이어마다 하나씩)로, 형태는 (batch_size, num_heads, sequence_length, sequence_length)입니다.

디코더의 어텐션 가중치, 어텐션 소프트맥스 이후, 자기 어텐션 헤드에서 가중 평균을 계산하는 데 사용됩니다.

* `cross_attentions` (tuple(torch.FloatTensor), 선택적, output_attentions=True가 전달되거나 config.output_attentions=True일 때 반환됨) — torch.FloatTensor의 튜플 (각 레이어마다 하나씩)로, 형태는 (batch_size, num_heads, sequence_length, sequence_length)입니다.

디코더의 교차 어텐션 레이어의 어텐션 가중치, 어텐션 소프트맥스 이후, 교차 어텐션 헤드에서 가중 평균을 계산하는 데 사용됩니다.

* `encoder_last_hidden_state` (torch.FloatTensor 형태 (batch_size, sequence_length, hidden_size), 선택적) — 모델의 인코더 마지막 레이어 출력에서의 숨겨진 상태 시퀀스.

* `encoder_hidden_states` (tuple(torch.FloatTensor), 선택적, output_hidden_states=True가 전달되거나 config.output_hidden_states=True일 때 반환됨) — torch.FloatTensor의 튜플 (모델에 임베딩 레이어가 있는 경우 임베딩 출력 + 각 레이어의 출력)로, 형태는 (batch_size, sequence_length, hidden_size)입니다.

각 레이어 출력에서의 인코더의 숨겨진 상태와 선택적 초기 임베딩 출력.

* `encoder_attentions` (tuple(torch.FloatTensor), 선택적, output_attentions=True가 전달되거나 config.output_attentions=True일 때 반환됨) — torch.FloatTensor의 튜플 (각 레이어마다 하나씩)로, 형태는 (batch_size, num_heads, sequence_length, sequence_length)입니다.

인코더의 어텐션 가중치, 어텐션 소프트맥스 이후, 자기 어텐션 헤드에서 가중 평균을 계산하는 데 사용됩니다.
loc (torch.FloatTensor 형태 (batch_size,) 또는 (batch_size, input_size), 선택적) — 각 시계열의 컨텍스트 윈도우의 이동 값으로, 모델 입력을 동일한 크기로 제공하고 원래 크기로 다시 이동하는 데 사용됩니다.
scale (torch.FloatTensor 형태 (batch_size,) 또는 (batch_size, input_size), 선택적) — 각 시계열의 컨텍스트 윈도우의 스케일링 값으로, 모델 입력을 동일한 크기로 제공하고 원래 크기로 다시 스케일링하는 데 사용됩니다.
static_features (torch.FloatTensor 형태 (batch_size, feature size), 선택적) — 배치 내 각 시계열의 정적 특징으로, 추론 시 공변량에 복사됩니다.