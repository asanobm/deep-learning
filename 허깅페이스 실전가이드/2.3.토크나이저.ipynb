{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. 토크나이저\n",
    "\n",
    "자연어 처리에서 토크나이징은 매우 중요한 작업이랍신다. 토크나이징은 말뭉치를 토큰이라는 단위로 나누고, 필요하면 특수한 토큰을 추가하거나 불필요한 문자를 제거하는 등의 \n",
    "작업을 수행하는 것을 의미한다... 어... 손으로 하면 정말 재미 있을 것 같다. (ㅋㅋㅋ)\n",
    "\n",
    "\n",
    "**토크나이저의 이점**\n",
    "\n",
    "* **효율성**: 토크나이저는 빠르고 병렬화된 방식으로 텍스트를 처리할 수 있다. 대규모 데이터세트에 대한 전처리 시간을 단축할 수 있다.\n",
    "* **유연성**: 토크나이저는 다양한 텍스트 데이터세트에 대해 적용할 수 있다. 특정 언어, 특정 도메인, 특정 작업에 대해 특화된 토크나이저를 만들 수 있다.\n",
    "* **일관성**: 토크나이저는 일관된 방식으로 텍스트를 처리한다. 이를 통해 모델의 학습 및 평가 과정을 안정화할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1. PreTrainedTokenizer Class\n",
    "\n",
    "`PreTrainedTokenizer` 클래스는 토크나이저의 기본 클래스이다. 이 클래스는 다음과 같은 주요 메서드를 제공한다.\n",
    "\n",
    "* `vocab_files_names`: 단어 집합 파일의 이름과 경로를 포함하는 딕셔너리를 반환한다.\n",
    "* `preteaind_vocab_files_map`: 사전 학습된 단어 집합 파일의 매핑을 포함하는 딕셔너리를 반환한다. 키는 모델 이름이나 버전을, 값은 파일 이름과 경로를 나타낸다.\n",
    "* `pretrained_init_configuration`: 사전 학습된 토크나이저의 초기화 구성을 반환한다. 키는 모델 이름이나 버전, 값은 해당 모델의 토크나이저 구성을 나타낸다.\n",
    "* `max_model_input_sizes`: 모델의 최대 입력 길이를 지정하는 딕셔너리다. 키는 모델의 이름이나 버전을 값은 해당 모델의 최대 입력 길이를 나타내는 정수값을 입력한다. `None`을 입력하면 모델의 입력 길이에 제한이 없다는 것을 의미한다.\n",
    "* `model_max_length`: 토크나이저가 사용하는 모델의 최대 입력 길이를 지정한다. 이 값을 기준으로 입력 시퀀스를 자르거나 패딩한다.\n",
    "* `padding_side`: 패딩을 적용할 쪽을 지정한다. `left` 또는 `right` 값을 입력한다.\n",
    "* `truncation_side`: 입력 시퀀스가 `model_max_length`보다 길 경우 자를 쪽을 지정한다. `left` 또는 `right` 값을 입력한다.\n",
    "* `model_input_names`: 순전파에 입력되는 텐서들의 이름 목록을 설정한다. 예를 들어 BERT 모델의 경우 `input_ids`, `attention_mask`, `token_type_ids` 등이 있다.\n",
    "* `bos_token`: 문장의 시작을 나타내는 토큰을 지정한다.\n",
    "* `eos_token`: 문장의 끝을 나타내는 토큰을 지정한다.\n",
    "* `unk_token`: 알 수 없는 토큰을 나타내는 토큰을 지정한다.\n",
    "* `sep_token`: 문장의 분리를 나타내는 토큰을 지정한다.\n",
    "* `pad_token`: 패딩을 나타내는 토큰을 지정한다.\n",
    "* `cls_token`: 문장의 시작을 나타내는 토큰을 지정한다.\n",
    "* `mask_token`: 마스킹을 나타내는 토큰을 지정한다.\n",
    "* `additional_special_tokens`: 추가 특수 토큰을 지정한다.\n",
    "\n",
    "PreTrainedTokenizer는 원시 텍스트 데이터를 모델이 이해할 수 있는 형태로 변환하는 역할을 수행한다. 토큰화, 패딩, 잘라내기 등의 작업을 수행해 모델의 입력 데이터 준비를 도와준다. 또한 시작/종료 토큰, 분리 토큰, 패딩 토큰 등을 추가하여 모델이 텍스트 데이터를 올바르게 처리할 수 있도록 돕는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2. ModelTokenizer Class\n",
    "\n",
    "모델 설정과 마찬가지로 모델 아키텍처마다 사전 학습된 토크나이저를 제공한다. `ModelTokenizer` 클래스는 `PreTrainedTokenizer` 클래스를 상속받아 토크나이저를 초기화하고 텍스트 데이터를 모델 입력으로 변환하는 메서드를 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2182, 2003, 1996, 6251, 1045, 2215, 7861, 8270, 4667, 2015, 2005, 1012, 102]\n",
      "[CLS] here is the sentence i want embeddings for. [SEP]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "text = \"Here is the sentence I want embeddings for.\"\n",
    "encoded = tokenizer.encode(text, add_special_tokens=True)\n",
    "\n",
    "print(encoded)\n",
    "print(tokenizer.decode(encoded))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
